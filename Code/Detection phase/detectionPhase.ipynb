{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nStart with array of cells for each row\\n======================================\\nFirst row will be ignored => [Code | Student Name | English Name | 1 | 2 | 3]\\n\\nFor each row:\\n1- Check for user choosed method (OCR or features + classifier)\\n2- For the first 3 cells [Code | Student Name | English Name ] \\n    apply the method to it and push the result to output array\\n3- For the next 3 cells apply the following\\n\\ta) Check if it is ✓\\n\\tb) Else, check if it is (box)\\n\\tc) Else, check if it is -\\n\\td) Else, check if it is ?  ===> output will be empty cell with red background\\n\\te) Else, check if is a stacked vertical lines  ===> output will be number of this lines\\n\\tf) Else, check if it a stacked horizontal lines  ===> output will be number of this lines\\n\\tg) If all the previous didn't give an output, then use the method to detect numeric values\\n4- Final output should be an array with the following\\n\\t[Code, Arabic Name, English Name, First cell output, Second cell output, Third cell output]\\n\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Start with array of cells for each row\n",
    "======================================\n",
    "First row will be ignored => [Code | Student Name | English Name | 1 | 2 | 3]\n",
    "\n",
    "For each row:\n",
    "1- Check for user choosed method (OCR or features + classifier)\n",
    "2- For the first 3 cells [Code | Student Name | English Name ] \n",
    "    apply the method to it and push the result to output array\n",
    "3- For the next 3 cells apply the following\n",
    "\ta) Check if it is ✓\n",
    "\tb) Else, check if it is (box)\n",
    "\tc) Else, check if it is -\n",
    "\td) Else, check if it is ?  ===> output will be empty cell with red background\n",
    "\te) Else, check if is a stacked vertical lines  ===> output will be number of this lines\n",
    "\tf) Else, check if it a stacked horizontal lines  ===> output will be number of this lines\n",
    "\tg) If all the previous didn't give an output, then use the method to detect numeric values\n",
    "4- Final output should be an array with the following\n",
    "\t[Code, Arabic Name, English Name, First cell output, Second cell output, Third cell output]\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from commonfunctions import *\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import pytesseract\n",
    "\n",
    "import os\n",
    "os.environ[\"TESSDATA_PREFIX\"] = r'C:\\Users\\iiBesh00\\AppData\\Local\\Tesseract-OCR\\tessdata'\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Users\\iiBesh00\\AppData\\Local\\Tesseract-OCR\\tesseract.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getEnglishName(img):\n",
    "# \t'''\n",
    "# \timg: Original image\n",
    "# \t'''\n",
    "# \tgray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# \t# get the string from the image and split it to get the wanted part\n",
    "# \ttext = \"\"\n",
    "# \tif ara:\n",
    "# \t\tthreshImg = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "# \t\ttext = pytesseract.image_to_string(threshImg, lang=\"ara\")\n",
    "# \telse:\n",
    "# \t\ttext = pytesseract.image_to_string(gray)\n",
    "# \treturn text.split('\\n')[0]\n",
    "\n",
    "def getEnglishName(image):\n",
    "\t\"\"\"\n",
    "\tThis function will handle the core OCR processing of getting english name.\n",
    "\t\"\"\"\n",
    "\ttext = pytesseract.image_to_string(image, lang='eng')\n",
    "\treturn text.split('\\n')[0]\n",
    "\n",
    "def getArabicName(image):\n",
    "\t\"\"\"\n",
    "\tThis function will handle the core OCR processing of getting arabic name.\n",
    "\t\"\"\"\n",
    "\tgray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\tthreshImg = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "\ttext = pytesseract.image_to_string(threshImg, lang='ara')\n",
    "\treturn text.split('\\n')[0]\n",
    "\n",
    "def getCode(image):\n",
    "\t\"\"\"\n",
    "\tThis function will handle the core OCR processing of getting id number.\n",
    "\t\"\"\"\n",
    "\ttext = pytesseract.image_to_string(image, config='digits')\n",
    "\treturn text.split('\\n')[0]\n",
    "\n",
    "# img = cv2.imread(\"../Samples/Detection phase samples/code.png\")\n",
    "# print(getCode(img))\n",
    "# show_images([img])\n",
    "\n",
    "# img = cv2.imread(\"../Samples/Detection phase samples/english name.png\")\n",
    "# print(getEnglishName(img))\n",
    "# show_images([img])\n",
    "\n",
    "# img = cv2.imread(\"../Samples/Detection phase samples/arabic name3.png\")\n",
    "# print(getArabicName(img))\n",
    "# show_images([img])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectRightMark(img):\n",
    "\t'''\n",
    "\timg: Preprocessed image given to detect if it was right mark => True\n",
    "\t'''\n",
    "\n",
    "\terodeKernel = np.ones((3,3),np.uint8)\n",
    "\terosion = cv2.erode(img, erodeKernel, iterations=1)\n",
    "\n",
    "\tkernel = np.array([\n",
    "\t\t[0,0,0,0,0,0,1],\n",
    "\t\t[0,0,0,0,0,1,0],\n",
    "\t\t[0,0,0,0,1,0,0],\n",
    "\t\t[0,0,0,1,0,0,0],\n",
    "\t\t[0,0,1,0,0,0,0],\n",
    "\t\t[0,1,0,0,0,0,0],\n",
    "\t\t[1,0,0,0,0,0,0]\n",
    "\t], dtype=np.uint8)\n",
    "\n",
    "\tdiagonal = cv2.morphologyEx(erosion, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "\tdiagonalContours, _ = cv2.findContours(diagonal, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\tdiagonalResult = len(diagonalContours)\n",
    "\n",
    "\tverticalKernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1,15))\n",
    "\tvertical = cv2.morphologyEx(erosion, cv2.MORPH_OPEN, verticalKernel, iterations=1)\n",
    "\tverticalContours, _ = cv2.findContours(vertical, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\tverticalResult = len(verticalContours)\n",
    "\n",
    "\treturn (verticalResult == 1 and diagonalResult == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectVerticalLines(img):\n",
    "\t'''\n",
    "\timg: Preprocessed image given to detect if it was vertical line => number of lines\n",
    "\t'''\n",
    "\n",
    "\tverticalKernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1,15))\n",
    "\tvertical = cv2.morphologyEx(img, cv2.MORPH_OPEN, verticalKernel, iterations=1)\n",
    "\tverticalContours, _ = cv2.findContours(vertical, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\t\n",
    "\treturn len(verticalContours)\n",
    "\n",
    "def detectHorizontalLines(img):\n",
    "\t'''\n",
    "\timg: Preprocessed image given to detect if it was horizontal line => number of lines\n",
    "\t'''\n",
    "\n",
    "\thorizontalKernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15,1))\n",
    "\thorizontal = cv2.morphologyEx(img, cv2.MORPH_OPEN, horizontalKernel, iterations=1)\n",
    "\n",
    "\thorizontalContours, _ = cv2.findContours(horizontal, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\t\n",
    "\treturn len(horizontalContours)\n",
    "\n",
    "def detectBoxs(img):\n",
    "\t'''\n",
    "\timg: Preprocessed image given to detect if it was box => True\n",
    "\t'''\n",
    "\tverticals = detectVerticalLines(img)\n",
    "\thorizontals = detectHorizontalLines(img)\n",
    "\n",
    "\treturn (verticals == 2 and horizontals == 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectQuestionMark(img):\n",
    "\t'''\n",
    "\timg: Preprocessed image given to detect if it was question mark => True\n",
    "\t'''\n",
    "\tdetectedCircles = cv2.HoughCircles(img, cv2.HOUGH_GRADIENT, 1, 80, param1 = 20,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tparam2 = 9, minRadius = 10, maxRadius = 17) \n",
    "\t\n",
    "\treturn detectedCircles is not None and len(detectedCircles) == 1\n",
    "\t# Draw the circle on the original image\n",
    "\t# if detectedCircles is not None:\n",
    "\t# \tdetectedCircles = np.uint16(np.around(detectedCircles)) \n",
    "\t# \tfor pt in detectedCircles[0, :]: \n",
    "\t# \t\ta, b, r = pt[0], pt[1], pt[2] \n",
    "\t# \t\tcv2.circle(img, (a, b), r, (0, 255, 0), 2)\n",
    "\t# \t\tcv2.circle(img, (a, b), 1, (0, 0, 255), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectCell(img):\n",
    "\t'''\n",
    "\timg: Original cell from the table\n",
    "\treturn => Data of that cell after processing it\n",
    "\t'''\n",
    "\t# Preprocess the given image\n",
    "\tgray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\tgray = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "\timg_bin = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "\timg_bin = cv2.bitwise_not(img_bin)\n",
    "\timg_bin[0:7,:] = 0\n",
    "\timg_bin[-7:,:] = 0\n",
    "\timg_bin[:, 0:20] = 0\n",
    "\timg_bin[:, -20:] = 0\n",
    "\n",
    "\t# Try to detect right mark\n",
    "\trightMark = detectRightMark(img_bin)\n",
    "\tif rightMark:\n",
    "\t\treturn 5\n",
    "\t\n",
    "\t# Try to detect boxes\n",
    "\tbox = detectBoxs(img_bin)\n",
    "\tif box:\n",
    "\t\treturn 0\n",
    "\t\n",
    "\t# Try to detect question mark\n",
    "\tquestionMark = detectQuestionMark(img_bin)\n",
    "\tif questionMark:\n",
    "\t\treturn -1\n",
    "\t\n",
    "\t# Try to detect minus\n",
    "\thorizontalLines = detectHorizontalLines(img_bin)\n",
    "\tif horizontalLines == 1:\n",
    "\t\treturn 0\n",
    "\telif horizontalLines != 0:\n",
    "\t\treturn (5 - horizontalLines)\n",
    "\t\n",
    "\tverticalLines = detectVerticalLines(img_bin)\n",
    "\tif verticalLines != 0:\n",
    "\t\treturn verticalLines\n",
    "\n",
    "\t# Else => Empty cell\n",
    "\treturn -2\n",
    "\n",
    "\n",
    "# img = cv2.imread(\"../Samples/Detection phase samples/question mark.png\")\n",
    "# img = cv2.imread(\"../Samples/Detection phase samples/right.png\")\n",
    "# img = cv2.imread(\"../Samples/Detection phase samples/vertical lines.png\")\n",
    "# img = cv2.imread(\"../Samples/Detection phase samples/horizontal lines.png\")\n",
    "# img = cv2.imread(\"../Samples/Detection phase samples/empty.png\")\n",
    "# print(detectCell(img))\n",
    "# show_images([img])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectNumericValues(img):\n",
    "\t'''\n",
    "\timg: Original image\n",
    "\treturn => The number in that image\n",
    "\t'''\n",
    "\tgray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\tgray = cv2.resize(gray, (600,400))\n",
    "\tgray = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "\timg_bin = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "\timg_bin = cv2.bitwise_not(img_bin)\n",
    "\timg_bin[0:50,:] = 0\n",
    "\timg_bin[-50:,:] = 0\n",
    "\timg_bin[:, 0:50] = 0\n",
    "\timg_bin[:, -50:] = 0\n",
    "\n",
    "\tnum = pytesseract.image_to_string(img_bin, config=(\"-c tessedit\"\n",
    "                  \"_char_whitelist=0123456789\"\n",
    "                  \" --psm 10\"\n",
    "                  \" -l osd\"\n",
    "                  \" \"))\n",
    "\treturn num.split(\"\\n\")[0]\n",
    "\n",
    "# img = cv2.imread(\"../Samples/Detection phase samples/digits/8.png\")\n",
    "# print(detectNumericValues(img))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Code': '1180255', 'Student Name': 'فاطمة عصام محمد جاب الله', 'English Name': 'Mohamed Elsayed Ahmed Abdellatif', '1': '5', '2': -1, '3': 5}]\n"
     ]
    }
   ],
   "source": [
    "def detectionPhase(images):\n",
    "\t'''\n",
    "\timages: Array of cells ready to be detected\n",
    "\treturn => Data ready to be exported to excel sheet\n",
    "\t'''\n",
    "\t\n",
    "\t# images[i] => 3 | images[i+1] => 2 | images[i+2] => 1\n",
    "\t# images[i+3] => English Name\n",
    "\t# images[i+4] => Student Name\n",
    "\t# images[i+5] => Code\n",
    "\n",
    "\tfinalData = []\n",
    "\tfor i in range(0, len(images), 6):\n",
    "\t\tthirdCell = detectCell(images[i])\n",
    "\t\tsecondCell = detectCell(images[i+1])\n",
    "\t\tfirstCell = detectNumericValues(images[i+2])\n",
    "\n",
    "\t\tenglishName = getEnglishName(images[i+3])\n",
    "\t\tstudentName = getArabicName(images[i+4])\n",
    "\t\tcode = getCode(images[i+5])\n",
    "\t\t\n",
    "\t\tdata = \t{\n",
    "\t\t\"Code\": code,\n",
    "\t\t\"Student Name\": studentName,\n",
    "\t\t\"English Name\": englishName,\n",
    "\t\t\"1\": firstCell,\n",
    "\t\t\"2\": secondCell,\n",
    "\t\t\"3\": thirdCell\n",
    "\t\t}\n",
    "\t\tfinalData.append(data)\n",
    "\t\n",
    "\treturn finalData\n",
    "\n",
    "img1 = cv2.imread(\"../Samples/Detection phase samples/right1.png\")\n",
    "img2 = cv2.imread(\"../Samples/Detection phase samples/question mark3.png\")\n",
    "img3 = cv2.imread(\"../Samples/Detection phase samples/digits/5.png\")\n",
    "\n",
    "img4 = cv2.imread(\"../Samples/Detection phase samples/english name2.png\")\n",
    "img5 = cv2.imread(\"../Samples/Detection phase samples/arabic name3.png\")\n",
    "img6 = cv2.imread(\"../Samples/Detection phase samples/code1.png\")\n",
    "\n",
    "imgs = [img1, img2, img3, img4, img5, img6]\n",
    "print(detectionPhase(imgs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
