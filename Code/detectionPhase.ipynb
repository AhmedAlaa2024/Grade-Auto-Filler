{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nStart with array of cells for each row\\n======================================\\nFirst row will be ignored => [Code | Student Name | English Name | 1 | 2 | 3]\\n\\nFor each row:\\n1- Check for user choosed method (OCR or features + classifier)\\n2- For the first 3 cells [Code | Student Name | English Name ] \\n    apply the method to it and push the result to output array\\n3- For the next 3 cells apply the following\\n\\ta) Check if it is ✓\\n\\tb) Else, check if it is (box)\\n\\tc) Else, check if it is -  ===> check if the width of minus is less than half the cell width\\n\\td) Else, check if it is ?  ===> output will be empty cell with red background\\n\\te) Else, check if is a stacked vertical lines  ===> output will be number of this lines\\n\\tf) Else, check if it a stacked horizontal lines  ===> output will be number of this lines\\n\\tg) If all the previous didn't give an output, then use the method to detect numeric values\\n4- Final output should be an array with the following\\n\\t[Code, Arabic Name, English Name, First cell output, Second cell output, Third cell output]\\n\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Start with array of cells for each row\n",
    "======================================\n",
    "First row will be ignored => [Code | Student Name | English Name | 1 | 2 | 3]\n",
    "\n",
    "For each row:\n",
    "1- Check for user choosed method (OCR or features + classifier)\n",
    "2- For the first 3 cells [Code | Student Name | English Name ] \n",
    "    apply the method to it and push the result to output array\n",
    "3- For the next 3 cells apply the following\n",
    "\ta) Check if it is ✓\n",
    "\tb) Else, check if it is (box)\n",
    "\tc) Else, check if it is -  ===> check if the width of minus is less than half the cell width\n",
    "\td) Else, check if it is ?  ===> output will be empty cell with red background\n",
    "\te) Else, check if is a stacked vertical lines  ===> output will be number of this lines\n",
    "\tf) Else, check if it a stacked horizontal lines  ===> output will be number of this lines\n",
    "\tg) If all the previous didn't give an output, then use the method to detect numeric values\n",
    "4- Final output should be an array with the following\n",
    "\t[Code, Arabic Name, English Name, First cell output, Second cell output, Third cell output]\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from commonfunctions import *\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import pytesseract\n",
    "\n",
    "import os\n",
    "os.environ[\"TESSDATA_PREFIX\"] = r'C:\\Users\\iiBesh00\\AppData\\Local\\Tesseract-OCR\\tessdata'\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Users\\iiBesh00\\AppData\\Local\\Tesseract-OCR\\tesseract.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCodeOrName(img, ara=False):\n",
    "\t'''\n",
    "\timg: Gray level image\n",
    "\tara: False for codes and english names, True for arabic name\n",
    "\t'''\n",
    "\t# get the string from the image and split it to get the wanted part\n",
    "\ttext = \"\"\n",
    "\tif ara:\n",
    "\t\t_, threshImg = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\t\ttext = pytesseract.image_to_string(threshImg, lang=\"ara\")\n",
    "\telse:\n",
    "\t\ttext = pytesseract.image_to_string(img)\n",
    "\treturn text.split('\\n')[0]\n",
    "\n",
    "# img = cv2.imread(\"./Samples/Detection phase samples/code.png\", cv2.IMREAD_GRAYSCALE)\n",
    "# print(getCodeOrName(img))\n",
    "# show_images([img])\n",
    "\n",
    "# img = cv2.imread(\"./Samples/Detection phase samples/english name.png\", cv2.IMREAD_GRAYSCALE)\n",
    "# print(getCodeOrName(img))\n",
    "# show_images([img])\n",
    "\n",
    "# img = cv2.imread(\"./Samples/Detection phase samples/arabic name2.png\", cv2.IMREAD_GRAYSCALE)\n",
    "# print(getCodeOrName(img, True))\n",
    "# show_images([img])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 2\n"
     ]
    }
   ],
   "source": [
    "def detectVerticalLines(img):\n",
    "\tdens = np.sum(img, axis=0)\n",
    "\tmean = np.mean(dens)\n",
    "\n",
    "\tthresh = 255 * np.ones_like(img)\n",
    "\tk = 0.9\n",
    "\tfor idx, val in enumerate(dens):\n",
    "\t\tif val < k * mean:\n",
    "\t\t\tthresh[:,idx] = 0\n",
    "\t\n",
    "\tthresh[:, 0:20] = 255\n",
    "\tthresh[:, -20:] = 255\n",
    "\tthresh = 255 - thresh\n",
    "\n",
    "\tcontours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\treturn len(contours)\n",
    "\n",
    "def detectHorizontalLines(img):\n",
    "\timg = img > np.mean(img)\n",
    "\n",
    "\tdens = np.sum(img, axis=1)\n",
    "\tmean = np.mean(dens)\n",
    "\n",
    "\tthresh = 255 * np.ones_like(img)\n",
    "\tk = 0.9\n",
    "\tfor idx, val in enumerate(dens):\n",
    "\t\tif val < k * mean:\n",
    "\t\t\tthresh[idx,:] = 0\n",
    "\tthresh[0:7,:] = 255\n",
    "\tthresh[-5:,:] = 255\n",
    "\tthresh = 255 - thresh\n",
    "\t\n",
    "\tcontours, _ = cv2.findContours(thresh, cv2.RETR_FLOODFILL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\treturn len(contours)\n",
    "\n",
    "\n",
    "# img = cv2.imread(\"./Samples/Detection phase samples/vertical lines.png\", cv2.IMREAD_GRAYSCALE)\n",
    "# num = detectVerticalLines(img) # 3\n",
    "# num1 = detectHorizontalLines(img) # 0\n",
    "# print(num, num1)\n",
    "\n",
    "# img = cv2.imread(\"./Samples/Detection phase samples/vertical lines1.png\", cv2.IMREAD_GRAYSCALE)\n",
    "# num = detectVerticalLines(img) # 1\n",
    "# num1 = detectHorizontalLines(img) # 0\n",
    "# print(num, num1)\n",
    "\n",
    "# img = cv2.imread(\"./Samples/Detection phase samples/horizontal lines.png\", cv2.IMREAD_GRAYSCALE)\n",
    "# num = detectVerticalLines(img) # 0\n",
    "# num1 = detectHorizontalLines(img) # 2\n",
    "# print(num, num1)\n",
    "\n",
    "# img = cv2.imread(\"./Samples/Detection phase samples/horizontal lines1.png\", cv2.IMREAD_GRAYSCALE)\n",
    "# num = detectVerticalLines(img) # 0\n",
    "# num1 = detectHorizontalLines(img) # 4\n",
    "# print(num, num1)\n",
    "\n",
    "# detect box\n",
    "img = cv2.imread(\"./Samples/Detection phase samples/box.png\", cv2.IMREAD_GRAYSCALE)\n",
    "num = detectVerticalLines(img)\n",
    "num1 = detectHorizontalLines(img)\n",
    "print(num, num1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
