{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nStart with array of cells for each row\\n======================================\\nFirst row will be ignored => [Code | Student Name | English Name | 1 | 2 | 3]\\n\\nFor each row:\\n1- Check for user choosed method (OCR or features + classifier)\\n2- For the first 3 cells [Code | Student Name | English Name ] \\n    apply the method to it and push the result to output array\\n3- For the next 3 cells apply the following\\n\\ta) Check if it is ✓\\n\\tb) Else, check if it is (box)\\n\\tc) Else, check if it is -\\n\\td) Else, check if it is ?  ===> output will be empty cell with red background\\n\\te) Else, check if is a stacked vertical lines  ===> output will be number of this lines\\n\\tf) Else, check if it a stacked horizontal lines  ===> output will be number of this lines\\n\\tg) If all the previous didn't give an output, then use the method to detect numeric values\\n4- Final output should be an array with the following\\n\\t[Code, Arabic Name, English Name, First cell output, Second cell output, Third cell output]\\n\\n\""
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Start with array of cells for each row\n",
    "======================================\n",
    "First row will be ignored => [Code | Student Name | English Name | 1 | 2 | 3]\n",
    "\n",
    "For each row:\n",
    "1- Check for user choosed method (OCR or features + classifier)\n",
    "2- For the first 3 cells [Code | Student Name | English Name ] \n",
    "    apply the method to it and push the result to output array\n",
    "3- For the next 3 cells apply the following\n",
    "\ta) Check if it is ✓\n",
    "\tb) Else, check if it is (box)\n",
    "\tc) Else, check if it is -\n",
    "\td) Else, check if it is ?  ===> output will be empty cell with red background\n",
    "\te) Else, check if is a stacked vertical lines  ===> output will be number of this lines\n",
    "\tf) Else, check if it a stacked horizontal lines  ===> output will be number of this lines\n",
    "\tg) If all the previous didn't give an output, then use the method to detect numeric values\n",
    "4- Final output should be an array with the following\n",
    "\t[Code, Arabic Name, English Name, First cell output, Second cell output, Third cell output]\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from commonfunctions import *\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import pytesseract\n",
    "\n",
    "import os\n",
    "os.environ[\"TESSDATA_PREFIX\"] = r'C:\\Users\\iiBesh00\\AppData\\Local\\Tesseract-OCR\\tessdata'\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Users\\iiBesh00\\AppData\\Local\\Tesseract-OCR\\tesseract.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCodeOrName(img, ara=False):\n",
    "\t'''\n",
    "\timg: Gray level image\n",
    "\tara: False for codes and english names, True for arabic name\n",
    "\t'''\n",
    "\t# get the string from the image and split it to get the wanted part\n",
    "\ttext = \"\"\n",
    "\tif ara:\n",
    "\t\t_, threshImg = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\t\ttext = pytesseract.image_to_string(threshImg, lang=\"ara\")\n",
    "\telse:\n",
    "\t\ttext = pytesseract.image_to_string(img)\n",
    "\treturn text.split('\\n')[0]\n",
    "\n",
    "# img = cv2.imread(\"./Samples/Detection phase samples/code.png\", cv2.IMREAD_GRAYSCALE)\n",
    "# print(getCodeOrName(img))\n",
    "# show_images([img])\n",
    "\n",
    "# img = cv2.imread(\"./Samples/Detection phase samples/english name.png\", cv2.IMREAD_GRAYSCALE)\n",
    "# print(getCodeOrName(img))\n",
    "# show_images([img])\n",
    "\n",
    "# img = cv2.imread(\"./Samples/Detection phase samples/arabic name2.png\", cv2.IMREAD_GRAYSCALE)\n",
    "# print(getCodeOrName(img, True))\n",
    "# show_images([img])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD VERSION\n",
    "def detectVerticalLines(img):\n",
    "\tdens = np.sum(img, axis=0)\n",
    "\tmean = np.mean(dens)\n",
    "\n",
    "\tthresh = 255 * np.ones_like(img)\n",
    "\tk = 0.9\n",
    "\tfor idx, val in enumerate(dens):\n",
    "\t\tif val < k * mean:\n",
    "\t\t\tthresh[:,idx] = 0\n",
    "\t\n",
    "\tthresh[:, 0:20] = 255\n",
    "\tthresh[:, -20:] = 255\n",
    "\tthresh = 255 - thresh\n",
    "\t\n",
    "\tcontours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\treturn len(contours)\n",
    "\n",
    "def detectHorizontalLines(img):\n",
    "\timg = img > np.mean(img)\n",
    "\n",
    "\tdens = np.sum(img, axis=1)\n",
    "\tmean = np.mean(dens)\n",
    "\n",
    "\tthresh = 255 * np.ones_like(img)\n",
    "\tk = 0.9\n",
    "\tfor idx, val in enumerate(dens):\n",
    "\t\tif val < k * mean:\n",
    "\t\t\tthresh[idx,:] = 0\n",
    "\tthresh[0:7,:] = 255\n",
    "\tthresh[-5:,:] = 255\n",
    "\tthresh = 255 - thresh\n",
    "\n",
    "\tcontours, _ = cv2.findContours(thresh, cv2.RETR_FLOODFILL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\treturn len(contours)\n",
    "\n",
    "\n",
    "# img = cv2.imread(\"./Samples/Detection phase samples/vertical lines.png\", cv2.IMREAD_GRAYSCALE)\n",
    "# num = detectVerticalLines(img) # 3\n",
    "# num1 = detectHorizontalLines(img) # 0\n",
    "# print(num, num1)\n",
    "\n",
    "# img = cv2.imread(\"./Samples/Detection phase samples/vertical lines1.png\", cv2.IMREAD_GRAYSCALE)\n",
    "# num = detectVerticalLines(img) # 1\n",
    "# num1 = detectHorizontalLines(img) # 0\n",
    "# print(num, num1)\n",
    "\n",
    "# img = cv2.imread(\"./Samples/Detection phase samples/horizontal lines.png\", cv2.IMREAD_GRAYSCALE)\n",
    "# num = detectVerticalLines(img) # 0\n",
    "# num1 = detectHorizontalLines(img) # 2\n",
    "# print(num, num1)\n",
    "\n",
    "# img = cv2.imread(\"./Samples/Detection phase samples/horizontal lines1.png\", cv2.IMREAD_GRAYSCALE)\n",
    "# num = detectVerticalLines(img) # 0\n",
    "# num1 = detectHorizontalLines(img) # 4\n",
    "# print(num, num1)\n",
    "\n",
    "# # detect box\n",
    "# img = cv2.imread(\"./Samples/Detection phase samples/box.png\", cv2.IMREAD_GRAYSCALE)\n",
    "# num = detectVerticalLines(img)\n",
    "# num1 = detectHorizontalLines(img)\n",
    "# print(num, num1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "def detectRightMark(img):\n",
    "\t'''\n",
    "\timg: Gray level image given to detect if it was right mark => True\n",
    "\t'''\n",
    "\timg = cv2.GaussianBlur(img, (5,5), 0)\n",
    "\t_, img_bin = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "\timg_bin = 255 - img_bin\n",
    "\timg_bin[0:10,:] = 0\n",
    "\timg_bin[-10:,:] = 0\n",
    "\timg_bin[:, 0:20] = 0\n",
    "\timg_bin[:, -20:] = 0\n",
    "\n",
    "\terodeKernel = np.ones((3,3),np.uint8)\n",
    "\terosion = cv2.erode(img_bin, erodeKernel, iterations=1)\n",
    "\n",
    "\tkernel = np.array([\n",
    "\t\t[0,0,0,0,0,0,1],\n",
    "\t\t[0,0,0,0,0,1,0],\n",
    "\t\t[0,0,0,0,1,0,0],\n",
    "\t\t[0,0,0,1,0,0,0],\n",
    "\t\t[0,0,1,0,0,0,0],\n",
    "\t\t[0,1,0,0,0,0,0],\n",
    "\t\t[1,0,0,0,0,0,0]\n",
    "\t], dtype=np.uint8)\n",
    "\n",
    "\tdiagonal = cv2.morphologyEx(erosion, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "\tdiagonalContours, _ = cv2.findContours(diagonal, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\tdiagonalResult = len(diagonalContours)\n",
    "\n",
    "\tverticalKernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1,15))\n",
    "\tvertical = cv2.morphologyEx(erosion, cv2.MORPH_OPEN, verticalKernel, iterations=1)\n",
    "\tverticalContours, _ = cv2.findContours(vertical, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\tverticalResult = len(verticalContours)\n",
    "\n",
    "\treturn (verticalResult == 1 and diagonalResult == 1)\n",
    "\n",
    "img = cv2.imread(\"./Samples/Detection phase samples/right.png\", cv2.IMREAD_GRAYSCALE)\n",
    "print(detectRightMark(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "def detectVerticalLines(img):\n",
    "\t'''\n",
    "\timg: Gray level image given to detect if it was vertical line => number of lines\n",
    "\t'''\n",
    "\timg = cv2.GaussianBlur(img, (5,5), 0)\n",
    "\t_, img_bin = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "\timg_bin = 255 - img_bin\n",
    "\timg_bin[0:10,:] = 0\n",
    "\timg_bin[-10:,:] = 0\n",
    "\timg_bin[:, 0:20] = 0\n",
    "\timg_bin[:, -20:] = 0\n",
    "\n",
    "\tverticalKernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1,15))\n",
    "\tvertical = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, verticalKernel, iterations=1)\n",
    "\tverticalContours, _ = cv2.findContours(vertical, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\t\n",
    "\treturn len(verticalContours)\n",
    "\n",
    "def detectHorizontalLines(img):\n",
    "\t'''\n",
    "\timg: Gray level image given to detect if it was horizontal line => number of lines\n",
    "\t'''\n",
    "\timg = cv2.GaussianBlur(img, (5,5), 0)\n",
    "\t_, img_bin = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "\timg_bin = 255 - img_bin\n",
    "\timg_bin[0:10,:] = 0\n",
    "\timg_bin[-10:,:] = 0\n",
    "\timg_bin[:, 0:20] = 0\n",
    "\timg_bin[:, -20:] = 0\n",
    "\n",
    "\thorizontalKernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15,1))\n",
    "\thorizontal = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, horizontalKernel, iterations=1)\n",
    "\n",
    "\thorizontalContours, _ = cv2.findContours(horizontal, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\t\n",
    "\treturn len(horizontalContours)\n",
    "\n",
    "def detectBoxs(img):\n",
    "\t'''\n",
    "\timg: Gray level image given to detect if it was box => True\n",
    "\t'''\n",
    "\tverticals = detectVerticalLines(img)\n",
    "\thorizontals = detectHorizontalLines(img)\n",
    "\n",
    "\treturn (verticals == 2 and horizontals == 2)\n",
    "\n",
    "# img = cv2.imread(\"./Samples/Detection phase samples/vertical lines.png\", cv2.IMREAD_GRAYSCALE)\n",
    "# img = cv2.imread(\"./Samples/Detection phase samples/horizontal lines1.png\", cv2.IMREAD_GRAYSCALE)\n",
    "# img = cv2.imread(\"./Samples/Detection phase samples/box1.png\", cv2.IMREAD_GRAYSCALE)\n",
    "print(detectVerticalLines(img))\n",
    "print(detectHorizontalLines(img))\n",
    "print(detectBoxs(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def detectQuestionMark(img):\n",
    "\timg = cv2.GaussianBlur(img, (5,5), 0)\n",
    "\t_, img_bin = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "\timg_bin = 255 - img_bin\n",
    "\timg_bin[0:7,:] = 0\n",
    "\timg_bin[-7:,:] = 0\n",
    "\timg_bin[:, 0:20] = 0\n",
    "\timg_bin[:, -20:] = 0\n",
    "\tdetected_circles = cv2.HoughCircles(img_bin, cv2.HOUGH_GRADIENT, 1, 80, param1 = 20,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tparam2 = 9, minRadius = 10, maxRadius = 17) \n",
    "\t\n",
    "\treturn detected_circles is not None and len(detected_circles) == 1\n",
    "\t# Draw the circle on the original image\n",
    "\t# if detected_circles is not None:\n",
    "\t# \tdetected_circles = np.uint16(np.around(detected_circles)) \n",
    "\t# \tfor pt in detected_circles[0, :]: \n",
    "\t# \t\ta, b, r = pt[0], pt[1], pt[2] \n",
    "\t# \t\tcv2.circle(img, (a, b), r, (0, 255, 0), 2)\n",
    "\t# \t\tcv2.circle(img, (a, b), 1, (0, 0, 255), 3)\n",
    "\n",
    "\n",
    "# img = cv2.imread(\"./Samples/Detection phase samples/horizontal lines.png\")\n",
    "# img = cv2.imread(\"./Samples/Detection phase samples/vertical lines.png\")\n",
    "# img = cv2.imread(\"./Samples/Detection phase samples/right.png\")\n",
    "img = cv2.imread(\"./Samples/Detection phase samples/question mark.png\", cv2.IMREAD_GRAYSCALE)\n",
    "detectQuestionMark(img)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
